{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. PyTorch Fundamentals\n",
    "\n",
    "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()` = https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dimension\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dimension\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]],\n",
       "\n",
       "        [[4, 9, 9],\n",
       "         [0, 2, 9],\n",
       "         [8, 1, 9]],\n",
       "\n",
       "        [[3, 9, 9],\n",
       "         [4, 5, 3],\n",
       "         [3, 4, 5]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([\n",
    "                       [[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]],\n",
    "                       \n",
    "                       [[4, 9, 9], \n",
    "                        [0, 2, 9],\n",
    "                        [8, 1, 9]],\n",
    "                       \n",
    "                       [[3, 9, 9],\n",
    "                        [4, 5, 3],\n",
    "                        [3, 4, 5]]\n",
    "                       ])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Why random tensors?\n",
    "\n",
    "Random tensors are important becasue the way many neural networks learn is that they start with tensors full of random numbers adn then adjust those random numbers to better represent the data.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
    "\n",
    "Torch random tensors - https://pytorch.org/docs/stable/generated/torch.rand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0291, 0.0126, 0.4964, 0.5374],\n",
       "         [0.4959, 0.1349, 0.8851, 0.4474],\n",
       "         [0.9089, 0.9030, 0.1749, 0.9163]],\n",
       "\n",
       "        [[0.7399, 0.4727, 0.8327, 0.1583],\n",
       "         [0.0828, 0.4252, 0.6054, 0.2767],\n",
       "         [0.2498, 0.4760, 0.4862, 0.1348]],\n",
       "\n",
       "        [[0.6812, 0.6352, 0.7534, 0.9781],\n",
       "         [0.1090, 0.0714, 0.4613, 0.5836],\n",
       "         [0.5502, 0.8920, 0.8119, 0.5488]],\n",
       "\n",
       "        [[0.8526, 0.3333, 0.6652, 0.4518],\n",
       "         [0.4947, 0.8033, 0.2580, 0.1769],\n",
       "         [0.5355, 0.6820, 0.5936, 0.5303]],\n",
       "\n",
       "        [[0.4605, 0.5857, 0.2425, 0.7213],\n",
       "         [0.7931, 0.4795, 0.9763, 0.9852],\n",
       "         [0.2949, 0.0202, 0.4667, 0.5899]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size(3, 4) / shape(3, 4) -> size == shape\n",
    "random_tensor = torch.rand(5, 3, 4)\n",
    "\"\"\"\n",
    "5x3x4 TENSOR visualizing\n",
    "[\n",
    "    1->[\n",
    "            1  2  3   4\n",
    "        1->[1, 2, 3, 4],\n",
    "        2->[5, 6, 7, 8],\n",
    "        3->[9, 10, 11, 12],\n",
    "    ],\n",
    "    \n",
    "    2->[\n",
    "            1   2   3   4\n",
    "        1->[13, 14, 15, 16],\n",
    "        2->[17, 18, 19, 20],\n",
    "        3->[21, 22, 23, 24],\n",
    "    ],\n",
    "    \n",
    "    3->[\n",
    "            1  2  3  4\n",
    "        1->[0, 0, 0, 0],\n",
    "        2->[1, 1, 1, 1],\n",
    "        3->[2, 2, 2, 2],\n",
    "    ],\n",
    "    \n",
    "    4->[\n",
    "            1  2  3  4\n",
    "        1->[3, 3, 3, 3],\n",
    "        2->[4, 4, 4, 4],\n",
    "        3->[5, 5, 5, 5],            \n",
    "    ],\n",
    "    \n",
    "    5->[\n",
    "            1  2  3  4\n",
    "        1->[6, 6, 6, 6],\n",
    "        2->[7, 7, 7, 7],\n",
    "        3->[8, 8, 8, 8],\n",
    "    ],\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # height, width, color channel(R, G, B)\n",
    "# could also be written as color first\n",
    "# random_image_size_tensor = torch.rand(size=(3, 224, 224)) # color channel(R, G, B), height, width\n",
    "\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_image_size_tensor)\n",
    "\n",
    "# [ (244[  ])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7270, 0.4034, 0.9732],\n",
       "        [0.1597, 0.1024, 0.6792],\n",
       "        [0.0659, 0.9619, 0.6636],\n",
       "        [0.1648, 0.9772, 0.0360],\n",
       "        [0.9935, 0.2928, 0.9989],\n",
       "        [0.6254, 0.3001, 0.1952],\n",
       "        [0.3166, 0.0781, 0.4886],\n",
       "        [0.7980, 0.7030, 0.3476],\n",
       "        [0.7927, 0.7053, 0.0200],\n",
       "        [0.5008, 0.9826, 0.7377],\n",
       "        [0.0515, 0.3446, 0.7634],\n",
       "        [0.9737, 0.2344, 0.4610],\n",
       "        [0.3411, 0.8795, 0.9680],\n",
       "        [0.3264, 0.6403, 0.0752],\n",
       "        [0.1289, 0.7402, 0.4497],\n",
       "        [0.5911, 0.8050, 0.4398],\n",
       "        [0.8680, 0.9392, 0.2724],\n",
       "        [0.0636, 0.7364, 0.5026],\n",
       "        [0.1957, 0.2842, 0.0148],\n",
       "        [0.5995, 0.6897, 0.0348],\n",
       "        [0.3983, 0.5052, 0.0502],\n",
       "        [0.0826, 0.0304, 0.3351],\n",
       "        [0.3715, 0.8209, 0.6589],\n",
       "        [0.8318, 0.1929, 0.5835],\n",
       "        [0.3081, 0.9188, 0.1159],\n",
       "        [0.4375, 0.1031, 0.8880],\n",
       "        [0.0826, 0.7931, 0.0947],\n",
       "        [0.5923, 0.1590, 0.7538],\n",
       "        [0.0410, 0.4444, 0.9554],\n",
       "        [0.8520, 0.0843, 0.2266],\n",
       "        [0.7889, 0.9544, 0.3458],\n",
       "        [0.4851, 0.0933, 0.5498],\n",
       "        [0.0890, 0.7303, 0.0448],\n",
       "        [0.5661, 0.1649, 0.7190],\n",
       "        [0.1069, 0.3957, 0.8872],\n",
       "        [0.2626, 0.8052, 0.1086],\n",
       "        [0.4106, 0.9470, 0.7605],\n",
       "        [0.0214, 0.1877, 0.3623],\n",
       "        [0.7272, 0.9175, 0.9923],\n",
       "        [0.4604, 0.4048, 0.8476],\n",
       "        [0.5096, 0.4790, 0.7656],\n",
       "        [0.1003, 0.9237, 0.4186],\n",
       "        [0.2232, 0.3807, 0.9962],\n",
       "        [0.3468, 0.3577, 0.3394],\n",
       "        [0.5759, 0.3566, 0.4775],\n",
       "        [0.8893, 0.7219, 0.2661],\n",
       "        [0.1965, 0.4928, 0.0668],\n",
       "        [0.6602, 0.9865, 0.6235],\n",
       "        [0.5931, 0.6808, 0.7523],\n",
       "        [0.9792, 0.6929, 0.8572],\n",
       "        [0.6058, 0.7285, 0.4861],\n",
       "        [0.6439, 0.1711, 0.7671],\n",
       "        [0.7034, 0.7249, 0.9926],\n",
       "        [0.2273, 0.1062, 0.3725],\n",
       "        [0.1463, 0.4802, 0.6414],\n",
       "        [0.1427, 0.2481, 0.2235],\n",
       "        [0.6274, 0.8618, 0.6031],\n",
       "        [0.0879, 0.1114, 0.3474],\n",
       "        [0.2436, 0.9352, 0.4817],\n",
       "        [0.3889, 0.4772, 0.9908],\n",
       "        [0.7876, 0.7131, 0.6933],\n",
       "        [0.4200, 0.0041, 0.8359],\n",
       "        [0.9203, 0.2910, 0.1743],\n",
       "        [0.4050, 0.9783, 0.8073],\n",
       "        [0.2410, 0.8489, 0.0223],\n",
       "        [0.7451, 0.3092, 0.3251],\n",
       "        [0.6752, 0.8842, 0.5872],\n",
       "        [0.1072, 0.4306, 0.4084],\n",
       "        [0.8713, 0.8546, 0.4368],\n",
       "        [0.4104, 0.1817, 0.4103],\n",
       "        [0.7566, 0.3279, 0.5719],\n",
       "        [0.1791, 0.2319, 0.8760],\n",
       "        [0.7086, 0.2342, 0.1825],\n",
       "        [0.6331, 0.2294, 0.4885],\n",
       "        [0.9441, 0.1632, 0.0142],\n",
       "        [0.7938, 0.6825, 0.5597],\n",
       "        [0.3333, 0.9865, 0.6281],\n",
       "        [0.8875, 0.1400, 0.6374],\n",
       "        [0.3464, 0.2921, 0.7102],\n",
       "        [0.1991, 0.2343, 0.7368],\n",
       "        [0.0856, 0.8564, 0.9103],\n",
       "        [0.0688, 0.3454, 0.4703],\n",
       "        [0.5101, 0.7951, 0.5956],\n",
       "        [0.9921, 0.6420, 0.4034],\n",
       "        [0.1062, 0.3221, 0.0795],\n",
       "        [0.8004, 0.1531, 0.3838],\n",
       "        [0.3830, 0.9493, 0.2669],\n",
       "        [0.8691, 0.7666, 0.9051],\n",
       "        [0.9158, 0.9440, 0.0481],\n",
       "        [0.3359, 0.1206, 0.3674],\n",
       "        [0.4955, 0.1909, 0.9774],\n",
       "        [0.4309, 0.7543, 0.7762],\n",
       "        [0.2386, 0.0972, 0.6827],\n",
       "        [0.0822, 0.5536, 0.6031],\n",
       "        [0.8664, 0.1101, 0.6863],\n",
       "        [0.7984, 0.9362, 0.2146],\n",
       "        [0.7286, 0.7633, 0.8710],\n",
       "        [0.7336, 0.0682, 0.9123],\n",
       "        [0.5761, 0.9408, 0.0819],\n",
       "        [0.5339, 0.6035, 0.4513],\n",
       "        [0.8314, 0.0707, 0.5806],\n",
       "        [0.2354, 0.1485, 0.8370],\n",
       "        [0.1046, 0.7375, 0.3162],\n",
       "        [0.6254, 0.0917, 0.3691],\n",
       "        [0.1781, 0.6624, 0.2792],\n",
       "        [0.9826, 0.9832, 0.3650],\n",
       "        [0.4857, 0.6216, 0.8896],\n",
       "        [0.7521, 0.4014, 0.3604],\n",
       "        [0.5071, 0.9899, 0.1649],\n",
       "        [0.0526, 0.9677, 0.5519],\n",
       "        [0.6578, 0.6791, 0.6475],\n",
       "        [0.5659, 0.3715, 0.7244],\n",
       "        [0.8914, 0.0825, 0.3176],\n",
       "        [0.2873, 0.7059, 0.9902],\n",
       "        [0.4530, 0.5632, 0.0668],\n",
       "        [0.6149, 0.5571, 0.4145],\n",
       "        [0.7614, 0.9483, 0.6441],\n",
       "        [0.4750, 0.2604, 0.6230],\n",
       "        [0.9734, 0.6448, 0.6174],\n",
       "        [0.3118, 0.8420, 0.9503],\n",
       "        [0.6763, 0.1166, 0.2820],\n",
       "        [0.1007, 0.9231, 0.1658],\n",
       "        [0.1574, 0.6939, 0.2458],\n",
       "        [0.0051, 0.8393, 0.7226],\n",
       "        [0.9344, 0.1580, 0.8122],\n",
       "        [0.3894, 0.8703, 0.5290],\n",
       "        [0.3791, 0.1548, 0.1364],\n",
       "        [0.1805, 0.8102, 0.1077],\n",
       "        [0.9977, 0.7193, 0.9678],\n",
       "        [0.0954, 0.4844, 0.0614],\n",
       "        [0.8870, 0.9306, 0.2458],\n",
       "        [0.3600, 0.5682, 0.0740],\n",
       "        [0.9273, 0.4383, 0.7351],\n",
       "        [0.9462, 0.5273, 0.7865],\n",
       "        [0.7229, 0.5606, 0.0822],\n",
       "        [0.4534, 0.2442, 0.0498],\n",
       "        [0.3357, 0.4860, 0.6303],\n",
       "        [0.0647, 0.7223, 0.1555],\n",
       "        [0.4638, 0.8333, 0.2107],\n",
       "        [0.6039, 0.0099, 0.7529],\n",
       "        [0.9663, 0.8886, 0.0696],\n",
       "        [0.0173, 0.7831, 0.6865],\n",
       "        [0.4208, 0.5592, 0.4712],\n",
       "        [0.4805, 0.0420, 0.3994],\n",
       "        [0.6905, 0.6717, 0.3894],\n",
       "        [0.8601, 0.0311, 0.5477],\n",
       "        [0.1179, 0.4052, 0.8383],\n",
       "        [0.5651, 0.9807, 0.6080],\n",
       "        [0.4050, 0.1220, 0.9994],\n",
       "        [0.3698, 0.4933, 0.0779],\n",
       "        [0.5881, 0.9973, 0.4963],\n",
       "        [0.2450, 0.6349, 0.1847],\n",
       "        [0.7649, 0.2258, 0.7122],\n",
       "        [0.0942, 0.4865, 0.0748],\n",
       "        [0.8302, 0.1905, 0.6960],\n",
       "        [0.7486, 0.6387, 0.4833],\n",
       "        [0.0664, 0.7022, 0.5324],\n",
       "        [0.7135, 0.4708, 0.5221],\n",
       "        [0.1206, 0.6304, 0.2309],\n",
       "        [0.2680, 0.6977, 0.4935],\n",
       "        [0.0347, 0.0788, 0.3871],\n",
       "        [0.7651, 0.3684, 0.9019],\n",
       "        [0.6861, 0.3342, 0.7071],\n",
       "        [0.9791, 0.6165, 0.6603],\n",
       "        [0.8134, 0.7245, 0.1507],\n",
       "        [0.1441, 0.6505, 0.4769],\n",
       "        [0.2883, 0.8979, 0.7354],\n",
       "        [0.5680, 0.6079, 0.9145],\n",
       "        [0.7199, 0.0292, 0.1385],\n",
       "        [0.4816, 0.7444, 0.5405],\n",
       "        [0.2401, 0.5325, 0.6819],\n",
       "        [0.0931, 0.8781, 0.7200],\n",
       "        [0.8161, 0.2860, 0.8442],\n",
       "        [0.2281, 0.6587, 0.6319],\n",
       "        [0.1224, 0.6322, 0.2912],\n",
       "        [0.9463, 0.6705, 0.1523],\n",
       "        [0.0657, 0.5132, 0.6977],\n",
       "        [0.8456, 0.1633, 0.3780],\n",
       "        [0.1234, 0.4997, 0.5978],\n",
       "        [0.6842, 0.9338, 0.8432],\n",
       "        [0.6079, 0.7495, 0.3330],\n",
       "        [0.0794, 0.4831, 0.5190],\n",
       "        [0.4499, 0.1438, 0.9770],\n",
       "        [0.8849, 0.2877, 0.0455],\n",
       "        [0.9431, 0.3862, 0.0944],\n",
       "        [0.1192, 0.2748, 0.3408],\n",
       "        [0.3392, 0.8518, 0.6132],\n",
       "        [0.7171, 0.6163, 0.4032],\n",
       "        [0.8723, 0.3649, 0.8665],\n",
       "        [0.8662, 0.3037, 0.9312],\n",
       "        [0.8430, 0.2147, 0.7620],\n",
       "        [0.3092, 0.0642, 0.0693],\n",
       "        [0.8340, 0.2283, 0.1884],\n",
       "        [0.8677, 0.6005, 0.7978],\n",
       "        [0.4339, 0.7379, 0.8901],\n",
       "        [0.3879, 0.9398, 0.6888],\n",
       "        [0.4702, 0.8531, 0.0226],\n",
       "        [0.9437, 0.7758, 0.3942],\n",
       "        [0.5351, 0.7243, 0.5878],\n",
       "        [0.4344, 0.3183, 0.8824],\n",
       "        [0.0697, 0.2960, 0.1470],\n",
       "        [0.9613, 0.6767, 0.1894],\n",
       "        [0.4924, 0.0347, 0.0038],\n",
       "        [0.4934, 0.6382, 0.0826],\n",
       "        [0.4175, 0.6980, 0.9275],\n",
       "        [0.2333, 0.0943, 0.6238],\n",
       "        [0.7860, 0.7829, 0.8479],\n",
       "        [0.4722, 0.1344, 0.0553],\n",
       "        [0.8623, 0.5467, 0.0322],\n",
       "        [0.9371, 0.4722, 0.3921],\n",
       "        [0.0190, 0.0160, 0.1459],\n",
       "        [0.5253, 0.8358, 0.9270],\n",
       "        [0.6746, 0.9366, 0.3418],\n",
       "        [0.6111, 0.6334, 0.2448],\n",
       "        [0.8217, 0.7548, 0.9707],\n",
       "        [0.8838, 0.6975, 0.1822],\n",
       "        [0.3711, 0.5001, 0.9609],\n",
       "        [0.7484, 0.4254, 0.1722],\n",
       "        [0.5370, 0.6087, 0.5742],\n",
       "        [0.5813, 0.6574, 0.7441],\n",
       "        [0.0068, 0.3826, 0.9794],\n",
       "        [0.9578, 0.2857, 0.6008],\n",
       "        [0.0860, 0.7696, 0.1788],\n",
       "        [0.9652, 0.2021, 0.1296]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# masking\n",
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Createa tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatype\n",
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.1000,  1.2000,  1.3000,  1.4000,  1.5000,  1.6000,  1.7000,\n",
       "         1.8000,  1.9000,  2.0000,  2.1000,  2.2000,  2.3000,  2.4000,  2.5000,\n",
       "         2.6000,  2.7000,  2.8000,  2.9000,  3.0000,  3.1000,  3.2000,  3.3000,\n",
       "         3.4000,  3.5000,  3.6000,  3.7000,  3.8000,  3.9000,  4.0000,  4.1000,\n",
       "         4.2000,  4.3000,  4.4000,  4.5000,  4.6000,  4.7000,  4.8000,  4.9000,\n",
       "         5.0000,  5.1000,  5.2000,  5.3000,  5.4000,  5.5000,  5.6000,  5.7000,\n",
       "         5.8000,  5.9000,  6.0000,  6.1000,  6.2000,  6.3000,  6.4000,  6.5000,\n",
       "         6.6000,  6.7000,  6.8000,  6.9000,  7.0000,  7.1000,  7.2000,  7.3000,\n",
       "         7.4000,  7.5000,  7.6000,  7.7000,  7.8000,  7.9000,  8.0000,  8.1000,\n",
       "         8.2000,  8.3000,  8.4000,  8.5000,  8.6000,  8.7000,  8.8000,  8.9000,\n",
       "         9.0000,  9.1000,  9.2000,  9.3000,  9.4000,  9.5000,  9.6000,  9.7000,\n",
       "         9.8000,  9.9000, 10.0000, 10.1000, 10.2000, 10.3000, 10.4000, 10.5000,\n",
       "        10.6000, 10.7000, 10.8000, 10.9000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use torch.range() and get deprecated message,  use torch.arange() instead\n",
    "one_to_ten = torch.arange(start=1, end=11, step=0.1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_to_ten), len(ten_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learnging: \n",
    "1. Tensor not right datatype\n",
    "2. Tensor not right shape\n",
    "3. Tensor not on right device\n",
    "\n",
    "\n",
    "- List of all datatypes in PyTorch - https://pytorch.org/docs/stable/tensors.html#data-types\n",
    "- Precision in computer science - https://en.wikipedia.org/wiki/Precision_(computer_science)#:~:text=In%20computer%20science%2C%20the%precision,used%20to%20express%20a%20value.\n",
    "\n",
    "TODO: READ ON TENSOR DATATYPES AND PRECISION IN COMPUTER SCIENCE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                               dtype=None, # what datatype is the tensor (e.g float32 or float16)\n",
    "                               device=None, # What device is your on? CPU or GPU(cuda)\n",
    "                               requires_grad=False # wether or not to track gradients with this tensors operations\n",
    "                               )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting datatypes in Pytorch\n",
    "float_16_tensor = float_32_tensor.type(torch.float16) # torch.half == torch.float16\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float16, torch.float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul = float_16_tensor * float_32_tensor\n",
    "\n",
    "mul.dtype, float_16_tensor.dtype, float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting inforamtion from Tensors (tensor attributes)\n",
    "\n",
    "1. Tensor not right datatype - to get datatype from a tensor, you can use `tensor.dype`\n",
    "2. Tensor not right shape - to get shape from a tensor, you can use `tensor.shape`\n",
    "3. Tensor not on right device - to get device from a tensor, you can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4223, 0.3523, 0.6990, 0.7067],\n",
       "        [0.3275, 0.5222, 0.7151, 0.2746],\n",
       "        [0.5995, 0.1966, 0.7319, 0.1155]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** _size_ and _shape_ of a **tensor** returns the same output but `torch.size()` is a function while `torch.shape` is an attibute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function Tensor.size>, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo here ⬇️⬇️⬇️⬇️⬇️\n",
    "some_tensor.size, some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4223, 0.3523, 0.6990, 0.7067],\n",
      "        [0.3275, 0.5222, 0.7151, 0.2746],\n",
      "        [0.5995, 0.1966, 0.7319, 0.1155]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device of tensor: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations incluse:\n",
    "* Addition\n",
    "* Substraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.6094, 10.0703, 10.1484, 10.3672, 10.5547], dtype=torch.float16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add to it\n",
    "\n",
    "tensor = torch.rand(5, dtype=torch.float16)\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0938, 0.7373, 1.4697, 3.6914, 5.5547], dtype=torch.float16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.3906, -9.9297, -9.8516, -9.6328, -9.4453], dtype=torch.float16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.0938, 0.7373, 1.4697, 3.6914, 5.5547], dtype=torch.float16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-built function\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main way of performing multiplication in neural network and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "- Matrix multiplication - https://www.mathsisfun.com/algebra/matrix-multiplying.\n",
    "- resource 2(visualizing) - http://matrixmultiplication.xyz\n",
    "\n",
    "\n",
    "There are two main rules that performing matrix multiplication needs to satisfy:\n",
    "1. The **inner dimensions** must much\n",
    "    * `(3, 2) @ (3, 2)` won't work ❌❌\n",
    "    * `(2, 3) @ (3, 2)` will work ✅✅\n",
    "    * `(3, 2) @ (2, 3)` will work ✅✅\n",
    "2. The resulting matrix has the shape of the **outer dimension**\n",
    "    * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "    * `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "new_tensor = torch.tensor([1, 2, 3])\n",
    "print(new_tensor, \"*\", new_tensor)\n",
    "print(f\"Equals: {new_tensor * new_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(new_tensor, new_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Marix multiplication by hand\n",
    "(1 * 1) + (2 * 2) + (3 * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(new_tensor)):\n",
    "    value += new_tensor[i] * new_tensor[i]\n",
    "    \n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: READ ON VECTORIZATION FOR OPTIMIZING CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.52 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(new_tensor, new_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most common error in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "\n",
    "# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code)\n",
    "torch.mm(tensor_A, tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shpar of one of the our tensors using `transpose`\n",
    "\n",
    "A **transpose** switches the axes or dimenson of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must much\n",
      "Output: \n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 5.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The matrix multiplication operation works when the tensor_B is transposed\n",
    "print(f\"Orginal shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must much\")\n",
    "print(\"Output: \\n\")\n",
    "\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum etc...(tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - note: the torch.mean() function requires a tensor of float32 or complex number dtype to work\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the position in tensor that has the minimum value with argmin() -> returns the index position of target tensor where the minimum value occurs\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the postion in the tensor that has the maximum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshaping an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted(swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a tensor\n",
    "import torch\n",
    "x = torch.arange(1., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change thev view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do vstack and hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimension from a target tensor\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "\n",
    "# remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f'\\nNew tensor: {x_squeezed}')\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target at a specific dim(dimension)\n",
    "print(f\"Previous target: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f'\\nNew tensor: {x_unsqueezed}')\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearrange the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
    "\n",
    "# permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\") # [color_channels, height, width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0111), tensor(0.0111))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0]= 0.0111\n",
    "x_original[0,0,0], x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from a tensor)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's index on out new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let index on the middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let index on the most inner bracket (last dimension)\n",
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also use \":\" to select \"all\" of a target dimension\n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th and 1st dimension but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "\n",
    "And because of this, PyTorh has the functionality to interact with it.\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # warning: when converting from numpy -> pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this to to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of tensor, what will this to to `numpy_tensor`?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update random number to try and make them better representations of the data -> again -> again -> again...`\n",
    "\n",
    "To reduce the randomness in neural network and PyTorch comes the concept of a **random seed**\n",
    "\n",
    "Essentially what the random seed does is \"flavour\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8760, 0.0275, 0.4761, 0.6723],\n",
      "        [0.6088, 0.8199, 0.7975, 0.2515],\n",
      "        [0.3248, 0.4903, 0.0232, 0.0914]])\n",
      "tensor([[0.4718, 0.8379, 0.8674, 0.8603],\n",
      "        [0.7515, 0.1438, 0.5605, 0.9017],\n",
      "        [0.4879, 0.6321, 0.9639, 0.4796]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Crete 2 random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra resources for reproducibility\n",
    "* https://pytorch.org/docs/stable/notes/randomness.html\n",
    "* https://en.wikipedia.org/wiki/Random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Let's make some random but reproducible tensors\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to everything hunky dory(good).\n",
    "\n",
    "### 1.  Getting a GPU\n",
    "\n",
    "1. Easiest -  Use Google Colab for free GPU (options to upgrade as well)\n",
    "2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU,  there's lots of options...\n",
    "3. Use could computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them\n",
    "\n",
    "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documentaton: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For PyTorch since it's capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
    "\n",
    "\n",
    "E.g. run GPU if available, else default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU\n",
    "\n",
    "The reason we want our tensors/models on the GPU because using GPU results in faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# creat a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# tensor no on gpu\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move tensor to gpu (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if tensor is on the GPU can't transform it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix the GPU tensor with numpy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercies & Extra-curriculum\n",
    "\n",
    "See excerciesfot this notebook here: https:www.learnpytorch.io/00_pytorch_fundamentals/#exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sophia-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
